\chapter{Background}
The three core mechanisms used for dynamically adjusting stream processing in this thesis are Service Level Objectives (SLOs), Elasticity and Active Inference (AIF). This chapter introduces foundational concepts, essential for understanding how Active Inference
can be effectively leveraged to uphold Service Level Objectives (SLOs) in resource-constrained
edge computing environments. The first section establishes the critical role of SLOs in edge computing scenarios. The subsequent section defines the role of Elasticity in Edge Computing Systems. The penultimate section explores all of the key concepts regarding Active Inference and the Free Energy Principle. The final section discusses the principles for using AIF in distributed systems.

\section{Edge Computing and Service Level Objectives}
Edge computing refers to a distributed computing paradigm in which data processing occurs in
close proximity to the data source. This architectural shift reduces the latency and bandwidth
limitations inherent in centralized cloud computing \cite{deng_edge_2020}, while enabling real-time
analytics for latency-sensitive tasks such as autonomous driving, smart surveillance, and
industrial automation \cite{zhang_octopus_2023}.

Edge computing environments are characterized by pronounced heterogeneity \cite{furst_elastic_2018} , i.e, resource-asymmetry, vendor specifications, and usage patterns \cite{danilenka_adaptive_2025}. Devices may range from embedded computing boards to more capable edge servers, each
with distinct resource constraints in terms of CPU, memory, energy, bandwidth and especially GPU, which has become a significant factor due to increasing inference demand. When tasked with continuous stream
processing (e.g., real-time video analysis), such systems must dynamically manage
computational demands without the luxury of cloud-level resource elasticity.

To formalize quality expectations in such constrained environments, Service Level Objectives
(SLOs) are used \cite{casamayor_pujol_deepslos_2024}. SLOs define quantifiable thresholds on performance metrics, such as
response time, memory usage, or energy consumption targets \cite{danilenka_adaptive_2025}. SLOs serve as internal optimization goals \cite{danilenka_adaptive_2025} to guide system behavior under varying load conditions \cite{nastic_sloc_2020}.
For example, in a video inference pipeline, one
might define an SLO that memory usage must remain below 80\% of available capacity.

Crucially, SLOs can serve a dual role: they can be targets for optimization and/or constraints that the
system must not violate \cite{casamayor_pujol_deepslos_2024}, \cite{sedlak_diffusing_2024}. In edge scenarios, where stream quality competes directly with resource availability, such as video streaming tasks \cite{sedlak_adaptive_2024}, SLO-aware control is essential \cite{sedlak_slo-aware_2025}.

\section{Elasticity in Edge Computing Systems}
Elasticity refers to a system’s ability to automatically adapt to changing workloads and resource availability. Since edge devices typically operate under fixed compute budgets, scaling hardware resources is not an option. Thus, elasticity must be achieved through intelligent control of software parameters \cite{sedlak_towards_2025}.

Sedlak et al. define elasticity in \cite{sedlak_towards_2025} along multiple axes:
\begin{itemize}
  \item \textbf{Quality Elasticity} — adjusts application-level parameters such as resolution, FPS,
or inference model complexity
  \item \textbf{Resource Elasticity} — modulates CPU, memory, or I/O usage
  \item \textbf{Cost Elasticity} — optimizes for energy efficiency or execution time.
\end{itemize}

Each elasticity action impacts both the system's SLO fulfillment and its Quality of Experience
(QoE). For instance, reducing the inference model complexity alleviates computational load but may lead to less accurate results. The key challenge lies in selecting the most appropriate elasticity action under uncertainty, while maintaining SLO compliance and maximizing QoE.

Traditional control mechanisms, such as threshold-based rules, static policies or Mache Learning approaches are not optimal to address this trade-off in dynamic environments \cite{sedlak_active_2024}. A model-based approach, capable of learning and adapting to evolving contexts, is therefore required \cite{sedlak_equilibrium_2024}, \cite{danilenka_adaptive_2025}.

\section{Active Inference and the Free Energy Principle}
\subsection{The Free Energy Principle}
The Free Energy Principle (FEP), as defined in \cite{friston_free-energy_2010}, provides a unified
theory of perception, action, and learning. It posits that any self-organizing system that
maintains equilibrium with its environment over time must minimize the long-term divergence between its
internal beliefs and external sensory states \cite{friston_active_2017}. This divergence, known as
surprise, refers to the difference between what an agent predicts based on its internal model and what it observes in the environment \cite{sedlak_adaptive_2024}.

Agents cannot minimize surprise directly, since the actual way that the world produces sensory data
is unknown. This causal process that describes how external states of the world generate observable
outcomes is known as the generative process \cite{friston_free-energy_2010}. As an agent is unable to observe the "real world", it instead creates an internal representation of the generative process, known as the generative model. The closer the generative model is to the underlying generative process, the higher the precision of the agent's predictions is \cite{sedlak_active_2024}.

As the generative model is typically an approximation of the real world and thus cannot minimize surprise directly, agents aim to minimize an upper bound known as (variational) Free Energy (FE) instead. It captures the difference between the systems internal representation of the world and its observations, making it a computationally feasible approximation for surprise.

Variational Free Energy (FE) can be expressed as the Kullback-Leibler (KL) divergence between approximate posterior probability (Q) of hidden states (x) and their exact posterior probability (P) \cite{sedlak_active_2024}, \cite{sedlak_adaptive_2024}, \cite{sajid_active_2021}. 
\[FE = TODO Formula and variables for Free Energy\]

 minimizing free energy minimizes KL divergence and brings the agent’s beliefs closer to the true posterior distribution \(TODO: Distribution Variables here\).

 \subsection{Expected Free Energy}
To act in the world, agents must not only evaluate current states but also anticipate the outcomes of future actions. This is done via Expected Free Energy (EFE). EFE)extends the concept of variational free energy into the future, by evaluating possible future action sequences using a policy \(\pi\). \cite{friston_active_2016}. The agent uses the EFE to decide on actions. EFE is made up of two key components \cite{friston_active_2022} % Active Inference: The Free Energy Principle in Mind, Brain, and Behavior%
\begin{enumerate}
  \item \textbf{Epistemic Value (Information Gain)} — Drives exploration by favoring actions that are expected to yield informative outcomes, improving the agent’s generative model.
  \item \textbf{Pragmatic Value} — Drives the agent to select actions that are likely to fulfill its explicit goals or preferences, i.e., it promotes exploitation.
\end{enumerate}

Together, these terms enable the agent to balance the classic exploration-exploitation tradeoff \cite{sedlak_adaptive_2024}. This dual drive allows AIF
agents to maintain SLOs while learning optimal control strategies for software parameters. \cite{lapkovskis_benchmarking_2025}.

\subsection{Active Inference}
Active inference (AIF) operationalizes the Free Energy Principle in artificial agents, extending it to encompass both state estimation and action selection \cite{lanillos_active_2021}, \cite{sedlak_equilibrium_2024}. To implement the concepts of the Free Energy Principle, an agent maintains a generative model, an internal representation of the world that the agent operates in. 

\todo{Add figure depicting Active Infernece}


\subsection{The Active Inference Cycle}




posits that intelligent agents maintain internal generative models of
their environment and use them to predict sensory inputs, select actions, and update beliefs
over time. 

\section{Active Inference in Distributed Systems}

