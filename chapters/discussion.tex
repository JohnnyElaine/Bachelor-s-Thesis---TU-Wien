\chapter{Discussion}
\label{chap:discussion}
This chapter interprets the results of the evaluation in the context of the research questions posed in Chapter~\ref{sec:research-question}. Additional sections discuss the impact of slow worker nodes and explore avenues for decentralized control through local Active Inference agents.

\section{Revisiting the Research Questions}
\subsection{Efficient Stream Processing}

\textbf{RQ1:} \textit{How can streaming data be processed efficiently in edge computing systems with heterogeneous computational resources?}

The prototype demonstrates that distributed stream processing enables high resource efficiency even under heterogeneous node capacities. In the base scenario A, worker nodes with varying compute budgets collectively maintained a SLO compliance of over 98\% for both agents. Task parallelism and stream segmentation allow balanced utilization across constrained nodes, resulting in a task distribution in accordance with the workers' capabilities.

\subsection{Elasticity Mechanisms}

\textbf{RQ2:} \textit{How can elasticity be implemented by adapting stream service parameters to manage computational load?}

Elasticity was realized by dynamically adjusting three video stream parameters: FPS, resolution, and inference quality. The producer continuously monitored system metrics and adjusted parameters to avoid SLO violations. 

In all evaluated scenarios, the controller adapted effectively to dynamic conditions. For instance, in Scenario C, the system halved the compute budget and maintained SLOs by reducing stream parameters. 

\subsection{Control via Active Inference}

\textbf{RQ3:} \textit{How can an Active Inference agent be used to select stream configurations that balance SLO enforcement and output quality?}

The AIF agent operates under a generative model that predicts the consequences of actions on SLO values. By minimizing expected free energy, it selects configurations that reduce long-term surprise, i.e., SLO violations, while maximizing QoE where possible.

Evaluation shows the AIF agent prefers conservative, stable configurations. In Scenario B, it prevented violations during load spikes by proactively reducing FPS. Compared to the heuristic, it responded more cautiously and restored quality more slowly.

This behavior reflects the dual objectives encoded in the AIF agent: maintaining belief confidence (epistemic value) and fulfilling preferences (pragmatic value). It illustrates the benefit of model-based control for sustainable adaptation.

\subsection{Trade-off Analysis}

\textbf{RQ4:} \textit{What are the trade-offs between upholding SLOs and maximizing Quality of Experience (QoE) in dynamic and resource-limited scenarios?}

A clear trade-off emerges across all scenarios. The AIF agent prioritized SLO compliance over stream quality. In Scenario C, it reduced stream quality by 19\% to uphold a 90.6\% global SLO fulfillment rate. The heuristic agent, in contrast, favored higher QoE but incurred longer violation streaks.

These results highlight a structural tension in edge environments: high QoE increases computational cost, risking SLO violations. The AIF agent navigates this trade-off through principled inference rather than reactive rules, but its conservative behavior delays quality restoration after load drops.

This suggests that agent design must carefully balance exploration and exploitation, and future work may explore adaptive preference weighting or multi-objective formulations.

\section{Impact of Slow Worker Nodes on Stream Integrity}

While the load balancing strategy employed in this system ensures effective utilization of heterogeneous resources, it does not fully mitigate the detrimental effects of extremely slow worker nodes. In particular, a critical failure mode arises when a worker is consistently unable to process tasks within the temporal bounds defined by the stream's latency constraints.

Consider a video stream operating at 30 FPS, which implies that a new frame is produced every \(33\,\text{ms}\). If the system tolerates an end-to-end delay of \(1\,\text{s}\), then each worker has at most \(1\,\text{s}\) to complete the processing of an individual task. When a worker exceeds this time budget, the result of its computation is rendered obsolete by the time it reaches the collector. Specifically, if the processed task arrives with a lower task identifier than the most recently aggregated frame, it will be discarded by the collector to maintain temporal consistency in the output stream.

This scenario leads to two significant issues: (1) a loss of information, as frames from the original stream are effectively dropped, and (2) wasted computational effort, as the processing resources of the slow worker node contribute no value to the final output. Both effects degrade the overall Quality of Experience (QoE) of the system and reduce processing efficiency.

To address this problem, the system enforces a Service Level Objective (SLO) based on the worker with the highest average processing time. This metric is continuously monitored, and if a worker's processing time exceeds a predefined threshold, the producer dynamically reconfigures the stream parameters (e.g., reducing resolution or FPS) to reduce the computational load. 

However, this solution introduces a trade-off: when a single underperforming node fails to keep pace, it may trigger a global quality degradation affecting all workers. Consequently, the QoE of the entire system is diminished due to the limitations of one component. This illustrates the importance of developing more refined mitigation strategies, such as selectively excluding persistently underperforming workers or incorporating adaptive deadlines that allow for differentiated task discarding thresholds.

\section{Decentralized Inference Optimization: Active Inference on Worker Nodes}

An interesting direction for future work involves deploying Active Inference (AIF) agents locally on worker nodes to optimize inference quality settings in a decentralized manner. While the current implementation centralizes control logic within the producer node, this approach could be extended by equipping workers with autonomous decision-making capabilities, particularly for optimizing their internal configurations.

Each worker would model the relationship between inference settings, such as YOLOv11 model variants (small, medium, large) and the quality of its local output (e.g., object detection accuracy, false positives). Using the AIF framework, the worker would learn a generative model that encodes how different inference configurations affect the output quality under varying input conditions.

In practice, this could reveal scenarios where a lightweight YOLOv11 model yields near-identical detection accuracy compared to a heavier model, despite significantly reduced resource consumption. Such insights are task- and input-dependent and may vary over time. For instance, under good lighting conditions or in scenes with low visual complexity, a small model may perform adequately. Conversely, more complex or noisy inputs may require higher-capacity models.

Once the local AIF agent infers its preferred configuration, it communicates this preference to the producer. The producer aggregates preferences from all worker nodes and selects a globally consistent configuration that satisfies the preferences while upholding global resource constraints and Service Level Objectives (SLOs). This architecture enables dynamic adaptation not only at the stream level but also at the granularity of individual worker nodes, potentially improving overall resource efficiency and detection performance.

This introduces the potential for hierarchical active inference architectures, where local beliefs influence global decision-making. However, such a distributed control model also raises challenges in preference aggregation, conflict resolution, and communication overhead, which merit further investigation.
